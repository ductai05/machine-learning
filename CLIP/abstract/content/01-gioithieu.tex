\section{Tóm tắt}

\paragraph{}{Chúng tôi lựa chọn \textbf{Hướng 2: Nghiên cứu một bài báo khoa học} với lý do sau:}

\begin{itemize}
    \item Nâng cao hiểu biết về các mô hình cơ bản, quan trọng trong lĩnh vực Machine learning / Deep learning / AI. 
    \item Hiểu cách ứng dụng của toán học và kĩ thuật lập trình trong nghiên cứu và thực tế.
    \item Tăng khả năng tự nghiên cứu và áp dụng tri thức mới vào thực tiễn.
    \item Nâng cao tư duy phản biện, phân tích, tổng hợp.
\end{itemize}

\paragraph{}{\textbf{CLIP} \cite{radford2021learning} (Contrastive Language-Image Pre-Training) là một mạng nơ-ron được huấn luyện trên nhiều cặp dữ liệu (ảnh, văn bản). Mô hình này có thể được hướng dẫn bằng ngôn ngữ tự nhiên để dự đoán đoạn văn bản phù hợp nhất với một hình ảnh, mà không cần được tối ưu hóa trực tiếp cho nhiệm vụ đó — tương tự như khả năng “zero-shot” (không cần huấn luyện lại) của GPT-2 và GPT-3.

CLIP đạt hiệu suất tương đương với ResNet-50 gốc trên bộ dữ liệu ImageNet theo cách “zero-shot”, mà không cần sử dụng bất kỳ ví dụ có gán nhãn nào trong 1,28 triệu ảnh ban đầu, từ đó vượt qua một số thách thức lớn trong lĩnh vực thị giác máy tính.

CLIP \cite{radford2021learning}, Code \cite{code_clip}, Blog \cite{blog_clip}.
}

\paragraph{}{\textbf{Lý do lựa chọn bài báo:}}

\begin{itemize}
    \item CLIP là một mô hình cơ sở (foundation model) quan trọng trong lĩnh vực học đa phương thức, kết nối giữa thị giác máy tính và xử lý ngôn ngữ tự nhiên.
    \item CLIP có ứng dụng đa dạng: truy vấn hình ảnh bằng văn bản; phân loại hình ảnh zero-shot và fewshot; phân tích nội dung video.
    \item CLIP được xây dựng dựa trên các kiến thức nền tảng toán học như đại số tuyến tính, xác suất thống kê. Hiểu rõ CLIP sẽ nâng cao kiến thức về toán học.
\end{itemize}

\paragraph{}{\textbf{Kế hoạch thực hiện:}}

\begin{enumerate}
    \item Phân tích các nền tảng của CLIP: Contrastive learning, Vision Transformer/Transformer, Embedding Vector Space,...
    \item Phân tích dữ liệu, cách huấn luyện CLIP, so sánh các mô hình.
    \item Các mô hình SOTA được phát triển thêm dựa trên CLIP: BLIP-2, BLIP3-o,... 
    \item Ứng dụng của CLIP vào cuộc thi truy vấn AI Challenge HCMC 2025.
\end{enumerate}